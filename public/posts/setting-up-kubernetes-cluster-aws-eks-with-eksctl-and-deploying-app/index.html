<!doctype html><html dir=ltr lang=en data-theme class="html theme--light"><head><title>|
Setting up a Kubernetes cluster on AWS EKS with eksctl and Deploying an App
</title><meta charset=utf-8><meta name=generator content="Hugo 0.124.1"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content><meta name=description content="JULIA FURST MORGADO
"><link rel=stylesheet href=/scss/main.min.1147aa5bacb4bce677a0e264073829caedb82fd18ea07a5f1d80521f539d1c45.css integrity="sha256-EUeqW6y0vOZ3oOJkBzgpyu24L9GOoHpfHYBSH1OdHEU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/custom.min.a435723c27c2e9a155a21a6ab80380c0d3a982912b7beabfa6274b2b55e0d456.css integrity="sha256-pDVyPCfC6aFVohpquAOAwNOpgpEre+q/pidLK1Xg1FY=" crossorigin=anonymous media=screen><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=https://juliafmorgado.com/posts/setting-up-kubernetes-cluster-aws-eks-with-eksctl-and-deploying-app/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script><script type=text/javascript src=/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Setting up a Kubernetes cluster on AWS EKS with eksctl and Deploying an App"><meta name=twitter:description content="It might come as a surprise, but not too long ago, configuring a Kubernetes cluster on Amazon EKS was quite challenging since you had to create all the components manually by yourself."><meta property="og:title" content="Setting up a Kubernetes cluster on AWS EKS with eksctl and Deploying an App"><meta property="og:description" content="It might come as a surprise, but not too long ago, configuring a Kubernetes cluster on Amazon EKS was quite challenging since you had to create all the components manually by yourself."><meta property="og:type" content="article"><meta property="og:url" content="https://juliafmorgado.com/posts/setting-up-kubernetes-cluster-aws-eks-with-eksctl-and-deploying-app/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-30T06:46:05+00:00"><meta property="article:modified_time" content="2024-03-30T06:46:05+00:00"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"Setting up a Kubernetes cluster on AWS EKS with eksctl and Deploying an App","headline":"Setting up a Kubernetes cluster on AWS EKS with eksctl and Deploying an App","alternativeHeadline":"","description":"
      
        It might come as a surprise, but not too long ago, configuring a Kubernetes cluster on Amazon EKS was quite challenging since you had to create all the components manually by yourself.


      


    ","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/juliafmorgado.com\/posts\/setting-up-kubernetes-cluster-aws-eks-with-eksctl-and-deploying-app\/"},"author":{"@type":"Person","name":"Julia Furst Morgado"},"creator":{"@type":"Person","name":"Julia Furst Morgado"},"accountablePerson":{"@type":"Person","name":"Julia Furst Morgado"},"copyrightHolder":{"@type":"Person","name":"Julia Furst Morgado"},"copyrightYear":"2024","dateCreated":"2024-03-30T06:46:05.96Z","datePublished":"2024-03-30T06:46:05.96Z","dateModified":"2024-03-30T06:46:05.96Z","publisher":{"@type":"Organization","name":"Julia Furst Morgado","url":"https://juliafmorgado.com/","logo":{"@type":"ImageObject","url":"https:\/\/juliafmorgado.com\/favicons\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/juliafmorgado.com\/posts\/setting-up-kubernetes-cluster-aws-eks-with-eksctl-and-deploying-app\/","wordCount":"2636","genre":["Tech"],"keywords":["AWS","EKS","Kubernetes"]}</script></head><body class=body><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=https://blog-imgs-23.s3.amazonaws.com/julia.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/></a></div><div class=sidebar__introduction-description><p>JULIA FURST MORGADO<br></p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://twitter.com/juliafmorgado target=_blank rel="noopener me" aria-label=Twitter title=Twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://www.linkedin.com/in/juliafmorgado target=_blank rel="noopener me" aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/juliafmorgado target=_blank rel="noopener me" aria-label=Github title=Github><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://www.youtube.com/c/JuliaFMorgado target=_blank rel="noopener me" aria-label=Youtube title=Youtube><i class="fab fa-youtube fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://www.instagram.com/juliafmorgado/ target=_blank rel="noopener me" aria-label=Instagram title=Instagram><i class="fab fa-instagram fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://www.tiktok.com/@juliafmorgado target=_blank rel="noopener me" aria-label="Tik Tok" title="Tik Tok"><i class="fab fa-tiktok fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Julia F Morgado 2024</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-H2FSKPLDX2"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-H2FSKPLDX2")</script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Blog</a></li><li class=nav__list-item><a href=/about/ title>About</a></li><li class=nav__list-item><a href=https://github.com/juliafmorgado/talks target=_blank rel="noopener noreferrer" title>Talks</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Setting Up a Kubernetes Cluster on AWS EKS With Eksctl and Deploying an App</h1><p>It might come as a surprise, but not too long ago, configuring a Kubernetes cluster on Amazon EKS was quite challenging since you had to create all the components manually by yourself. This changed with the introduction of <code>eksctl</code>, a tool written in Go by the community and sponsored by weaveworks that acts as the official AWS CLI for EKS management. <code>eksctl</code> allows for the creation and administration of clusters through YAML files, while leveraging CloudFormation stacks behind the scenes to handle the required resources. In this blog post you&rsquo;ll see that using <code>eksctl</code> simplifies the creation and deployment of Kubernetes clusters on Amazon EKS.</p><h2 id=installation>Installation</h2><p>Like other binaries written in Go, installation is super simple:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=n>curl</span> <span class=o>--</span><span class=n>silent</span> <span class=o>--</span><span class=n>location</span> <span class=s2>&#34;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz&#34;</span> <span class=o>|</span> <span class=n>tar</span> <span class=n>xz</span> <span class=o>-</span><span class=n>C</span> <span class=o>/</span><span class=n>tmp</span>
</span></span><span class=line><span class=cl><span class=n>sudo</span> <span class=n>mv</span> <span class=o>/</span><span class=n>tmp</span><span class=o>/</span><span class=n>eksctl</span> <span class=o>/</span><span class=n>usr</span><span class=o>/</span><span class=n>local</span><span class=o>/</span><span class=n>bin</span>
</span></span><span class=line><span class=cl><span class=n>eksctl</span> <span class=n>version</span>
</span></span></code></pre></div><p>Here&rsquo;s a breakdown of what the code snippet does:</p><ol><li>Downloads and extracts the <code>eksctl binary</code>:</li></ol><ul><li>The <code>curl</code> command fetches the latest <code>eksctl</code> binary from its GitHub releases page. This binary is compressed in a .tar.gz file for efficient transfer.</li><li><code>--silent --location</code>: These options ensure that the download process is not only quiet (no progress output) but also follows any redirects, which is crucial for reaching the final download link.</li><li>The URL contains a dynamic part, <code>$(uname -s)_amd64</code>, which automatically adjusts the download link based on your operating system (uname -s outputs your OS name, such as Linux or Darwin) and assumes an amd64 architecture.</li><li>The downloaded file is piped (<code>|</code>) into the <code>tar</code> command, which extracts the binary into the <code>/tmp</code> directory. This is a temporary location, safe for staging files before moving them to a more permanent location.</li></ul><ol start=2><li>Moves the binary to <code>/usr/local/bin</code>:</li></ol><ul><li>The <code>sudo mv /tmp/eksctl /usr/local/bin</code> command moves the extracted <code>eksctl</code> binary from <code>/tmp</code> to <code>/usr/local/bin</code>. This directory is commonly used for manually installed binaries and is typically included in the system&rsquo;s PATH. Placing <code>eksctl</code> here allows you to run it from any terminal without specifying its full path.</li><li>Using <code>sudo</code> is necessary because <code>/usr/local/bin</code> is a system directory, and modifying its contents requires administrative privileges.</li></ul><ol start=3><li>Verifies the installation<ul><li>Finally, running <code>eksctl version</code> checks the installed version of <code>eksctl</code>. This not only confirms that <code>eksctl</code> is correctly installed and accessible but also lets you know the exact version you have. It&rsquo;s a good practice to verify installations to ensure everything is set up as expected.</li></ul></li></ol><h2 id=configuring-an-aws-account>Configuring an AWS account</h2><p>Do not use your root account for cluster creation. In fact, avoid using your root account for anything other than creating other accounts or managing very specific AWS resources.</p><p>If it&rsquo;s your personal account, create another user. Now, if it&rsquo;s a corporate account, I suggest enabling AWS Organizations.</p><p>Create a new user in IAM with the following policies attached to it:</p><ul><li>AmazonEC2FullAccess</li><li>AWSCloudFormationFullAccess</li><li>EksFullAccess</li><li>IamLimitedAccess</li></ul><p>The first two are AWS-managed policies, so you don&rsquo;t need to create them. The last two will have the following content:</p><h3 id=eksallaccess>EksAllAccess</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>    &#34;Version&#34;: &#34;2012-10-17&#34;,
</span></span><span class=line><span class=cl>    &#34;Statement&#34;: [
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>            &#34;Effect&#34;: &#34;Allow&#34;,
</span></span><span class=line><span class=cl>            &#34;Action&#34;: &#34;eks:*&#34;,
</span></span><span class=line><span class=cl>            &#34;Resource&#34;: &#34;*&#34;
</span></span><span class=line><span class=cl>        },
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>            &#34;Action&#34;: [
</span></span><span class=line><span class=cl>                &#34;ssm:GetParameter&#34;,
</span></span><span class=line><span class=cl>                &#34;ssm:GetParameters&#34;
</span></span><span class=line><span class=cl>            ],
</span></span><span class=line><span class=cl>            &#34;Resource&#34;: [
</span></span><span class=line><span class=cl>                &#34;arn:aws:ssm:*:&lt;account_id&gt;:parameter/aws/*&#34;,
</span></span><span class=line><span class=cl>                &#34;arn:aws:ssm:*::parameter/aws/*&#34;
</span></span><span class=line><span class=cl>            ],
</span></span><span class=line><span class=cl>            &#34;Effect&#34;: &#34;Allow&#34;
</span></span><span class=line><span class=cl>        },
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>             &#34;Action&#34;: [
</span></span><span class=line><span class=cl>               &#34;kms:CreateGrant&#34;,
</span></span><span class=line><span class=cl>               &#34;kms:DescribeKey&#34;
</span></span><span class=line><span class=cl>             ],
</span></span><span class=line><span class=cl>             &#34;Resource&#34;: &#34;*&#34;,
</span></span><span class=line><span class=cl>             &#34;Effect&#34;: &#34;Allow&#34;
</span></span><span class=line><span class=cl>        },
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>             &#34;Action&#34;: [
</span></span><span class=line><span class=cl>               &#34;logs:PutRetentionPolicy&#34;
</span></span><span class=line><span class=cl>             ],
</span></span><span class=line><span class=cl>             &#34;Resource&#34;: &#34;*&#34;,
</span></span><span class=line><span class=cl>             &#34;Effect&#34;: &#34;Allow&#34;
</span></span><span class=line><span class=cl>        }        
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><h3 id=iamlimitedaccess>IamLimitedAccess</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>    &#34;Version&#34;: &#34;2012-10-17&#34;,
</span></span><span class=line><span class=cl>    &#34;Statement&#34;: [
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>            &#34;Effect&#34;: &#34;Allow&#34;,
</span></span><span class=line><span class=cl>            &#34;Action&#34;: [
</span></span><span class=line><span class=cl>                &#34;iam:CreateInstanceProfile&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:DeleteInstanceProfile&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:GetInstanceProfile&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:RemoveRoleFromInstanceProfile&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:GetRole&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:CreateRole&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:DeleteRole&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:AttachRolePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:PutRolePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:ListInstanceProfiles&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:AddRoleToInstanceProfile&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:ListInstanceProfilesForRole&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:PassRole&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:DetachRolePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:DeleteRolePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:GetRolePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:GetOpenIDConnectProvider&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:CreateOpenIDConnectProvider&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:DeleteOpenIDConnectProvider&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:TagOpenIDConnectProvider&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:ListAttachedRolePolicies&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:TagRole&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:GetPolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:CreatePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:DeletePolicy&#34;,
</span></span><span class=line><span class=cl>                &#34;iam:ListPolicyVersions&#34;
</span></span><span class=line><span class=cl>            ],
</span></span><span class=line><span class=cl>            &#34;Resource&#34;: [
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:instance-profile/eksctl-*&#34;,
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:role/eksctl-*&#34;,
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:policy/eksctl-*&#34;,
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:oidc-provider/*&#34;,
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:role/aws-service-role/eks-nodegroup.amazonaws.com/AWSServiceRoleForAmazonEKSNodegroup&#34;,
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:role/eksctl-managed-*&#34;
</span></span><span class=line><span class=cl>            ]
</span></span><span class=line><span class=cl>        },
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>            &#34;Effect&#34;: &#34;Allow&#34;,
</span></span><span class=line><span class=cl>            &#34;Action&#34;: [
</span></span><span class=line><span class=cl>                &#34;iam:GetRole&#34;
</span></span><span class=line><span class=cl>            ],
</span></span><span class=line><span class=cl>            &#34;Resource&#34;: [
</span></span><span class=line><span class=cl>                &#34;arn:aws:iam::&lt;account_id&gt;:role/*&#34;
</span></span><span class=line><span class=cl>            ]
</span></span><span class=line><span class=cl>        },
</span></span><span class=line><span class=cl>        {
</span></span><span class=line><span class=cl>            &#34;Effect&#34;: &#34;Allow&#34;,
</span></span><span class=line><span class=cl>            &#34;Action&#34;: [
</span></span><span class=line><span class=cl>                &#34;iam:CreateServiceLinkedRole&#34;
</span></span><span class=line><span class=cl>            ],
</span></span><span class=line><span class=cl>            &#34;Resource&#34;: &#34;*&#34;,
</span></span><span class=line><span class=cl>            &#34;Condition&#34;: {
</span></span><span class=line><span class=cl>                &#34;StringEquals&#34;: {
</span></span><span class=line><span class=cl>                    &#34;iam:AWSServiceName&#34;: [
</span></span><span class=line><span class=cl>                        &#34;eks.amazonaws.com&#34;,
</span></span><span class=line><span class=cl>                        &#34;eks-nodegroup.amazonaws.com&#34;,
</span></span><span class=line><span class=cl>                        &#34;eks-fargate.amazonaws.com&#34;
</span></span><span class=line><span class=cl>                    ]
</span></span><span class=line><span class=cl>                }
</span></span><span class=line><span class=cl>            }
</span></span><span class=line><span class=cl>        }
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p>Replace &lt;account_id> with your AWS account ID.</p><p>Now generate credentials for the user and keep the access key ID and secret key. <code>eksctl</code> requires the AWS CLI to be installed. If you don&rsquo;t have it installed, run:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>curl &#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&#34; -o &#34;awscliv2.zip&#34;
</span></span><span class=line><span class=cl>unzip awscliv2.zip
</span></span><span class=line><span class=cl>sudo ./aws/install
</span></span><span class=line><span class=cl>aws configure
</span></span></code></pre></div><p>You&rsquo;ll be prompted for details like the default AWS region (e.g., us-east-1), access key ID, and secret key to create the default profile. Now, if you already have the AWS CLI installed and configured, you can manually create the new profile by editing the <code>~/.aws/credentials</code> file.</p><p>Attention: when you have multiple profiles within your <code>~/.aws/credentials</code> file, specify which one you want to use by setting the value of the <code>AWS_PROFILE</code> variable with the command <code>export AWS_PROFILE=my_profile</code> and replacing <code>my_profile</code> with the name of the AWS profile you want to use. This ensures that any subsequent AWS CLI commands will use the credentials and configuration associated with the specified profile.</p><h2 id=creating-the-cluster>Creating the cluster</h2><p>By default, <strong>eksctl</strong> will create the cluster in a separate VPC using <strong>m5.large</strong> instances. This has some implications:</p><ul><li>By default quota, you can have a maximum of five VPCs per account;</li><li>If you&rsquo;re using a study, lab, or test environment, this type of instance can be considered somewhat expensive;</li><li>If you need the applications in the cluster to communicate with AWS resources - an instance in RDS, for example - located in another VPC, VPC Peering configuration and routes are necessary for this to happen.</li></ul><p>Our cluster will have the following characteristics:</p><ul><li>It will be called <strong>demo-eks</strong> and will be located in <strong>us-east-1</strong> (Northern Virginia);</li><li>Four subnets will be created in the new VPC, two public and two private. By default, <strong>eksctl</strong> allocates the cluster nodes in the private subnets;</li><li>A nodegroup called <strong>ng-01</strong> will be created with an auto scaling group, with a minimum of one instance and a maximum of 5 of type <strong>t3.medium</strong>;</li><li>IAM policies for <strong>external-dns, auto-scaling, cert-manager, ebs</strong>, and <strong>efs</strong>. We&rsquo;ll talk more about them shortly.</li></ul><p>Save the file below as <code>demo-eks.yaml</code> and then execute <code>eksctl create cluster -f demo-eks.yaml --kubeconfig=demo-eks-kubeconfig</code> and let the magic happen. <strong>eksctl</strong> will generate the stack (or stacks) within CloudFormation and create all the necessary resources, which will take about fifteen to twenty minutes (yes, it&rsquo;s a bit slow) and voilà, you&rsquo;ll have a Kubernetes cluster for use in AWS EKS, with credentials for access to it in the <code>demo-eks-kubeconfig.yaml</code> file.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: eksctl.io/v1alpha5
</span></span><span class=line><span class=cl>kind: ClusterConfig
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: demo-eks
</span></span><span class=line><span class=cl>  region: us-east-1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>managedNodeGroups:
</span></span><span class=line><span class=cl>  - name: ng-01
</span></span><span class=line><span class=cl>    instanceType: t3.medium
</span></span><span class=line><span class=cl>    desiredCapacity: 2
</span></span><span class=line><span class=cl>    minSize: 1
</span></span><span class=line><span class=cl>    maxSize: 5
</span></span><span class=line><span class=cl>    iam:
</span></span><span class=line><span class=cl>      withAddonPolicies:
</span></span><span class=line><span class=cl>        autoScaler: true
</span></span><span class=line><span class=cl>        externalDNS: true
</span></span><span class=line><span class=cl>        certManager: true
</span></span><span class=line><span class=cl>        ebs: true
</span></span><span class=line><span class=cl>        efs: true
</span></span></code></pre></div><blockquote><p>Important: If the <code>--kubeconfig</code> option is omitted, eksctl will generate the access file in <code>~/.kube/config</code>, which can be a problem if you already have other clusters configured. If that&rsquo;s the case, you can create a directory called <code>~/.kube/configs</code> to store the files and switch between them by setting the <code>KUBECONFIG</code> variable pointing to the desired file path (e.g., <code>export KUBECONFIG=${HOME}/.kube/configs/demo-eks-kubeconfig</code>). This step is essential for <code>kubectl</code> to be able to connect to the cluster.</p><p>If you&rsquo;re still getting an error suggesting that <code>kubectl</code> is trying to connect to a Kubernetes cluster on your local machine (localhost, IP address 127.0.0.1) instead of connecting to your Amazon EKS cluster, run the command <code>export KUBECONFIG=demo-eks-kubeconfig</code>.</p></blockquote><h2 id=helm-installation>Helm Installation</h2><p>You&rsquo;ve probably heard of Helm, but if not, don&rsquo;t worry. Helm is, in essence, a package manager for Kubernetes. These packages are provided in the form of charts, and with Helm, we can create manifests for our applications in a more dynamic, organized, parameterizable way, and then host them in repositories for deployment.</p><p>You can quickly install it using <code>curl</code>and <code>bash</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
</span></span></code></pre></div><p>Here&rsquo;s what the command does:</p><ol><li><p><code>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3</code>: This part of the command uses <code>curl</code>, a command-line tool for transferring data using various network protocols. Here, it&rsquo;s used to download the installation script for Helm 3 from its official GitHub repository. The URL points to the raw version of the <code>get-helm-3</code> script, which is intended to be executed directly.</p></li><li><p><code>| bash</code>: This pipe (|) takes the output of the <code>curl</code> command (which is the Helm 3 installation script) and feeds it directly into <code>bash</code>, the Bourne Again SHell. Running a script in this manner executes the script&rsquo;s contents.</p></li></ol><p>Here&rsquo;s what happens when you run the command:</p><ul><li>The <code>get-helm-3</code> script is fetched from the Helm GitHub repository using <code>curl</code>.</li><li>The script is then immediately executed in your shell (<code>bash</code>) without needing to be saved to a file on your disk.</li><li>The script performs several actions to install Helm 3:<ul><li>It checks your system to ensure it meets the prerequisites for installing Helm.</li><li>It determines the latest version of Helm 3 if not specified.</li><li>It downloads the correct Helm 3 binary for your operating system and architecture.</li><li>It places the Helm binary in a location on your system where executable files are typically stored, making it accessible from anywhere in your terminal.</li><li>It might also perform some additional setup tasks, such as setting up autocomplete features for Helm commands.</li></ul></li></ul><p>Or, if you&rsquo;re using a Debian-like distribution and want to use a package you can install it with the following commands:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg &gt; /dev/null
</span></span><span class=line><span class=cl>sudo apt-get install apt-transport-https --yes
</span></span><span class=line><span class=cl>echo &#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main&#34; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install helm
</span></span></code></pre></div><h2 id=add-ons-installation>Add-ons Installation</h2><h3 id=metrics-server>Metrics Server</h3><p>The <strong>Metrics Server</strong> is a necessary resource for using HPAs (Horizontal Pod Autoscalers). HPAs are extremely useful when we want to scale our applications horizontally when they need more resources.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
</span></span><span class=line><span class=cl>helm upgrade --install --create-namespace -n metrics-server metrics-server metrics-server/metrics-server
</span></span></code></pre></div><h3 id=prometheus>Prometheus</h3><p><strong>Prometheus</strong> is a monitoring solution. If you use Lens or another dashboard for monitoring your clusters, it will provide CPU, memory, network, and disk usage graphs for the cluster, nodes, controllers, and pods. Prometheus is commonly used alongside Grafana.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm repo add bitnami https://charts.bitnami.com/bitnami
</span></span><span class=line><span class=cl>helm install --create-namespace -n kube-prometheus prometheus bitnami/kube-prometheus
</span></span></code></pre></div><h3 id=externaldns>ExternalDNS</h3><p><strong>ExternalDNS</strong> synchronizes Kubernetes resources with external DNS records hosted on providers like AWS Route 53, Google Cloud DNS, AzureDNS, etc. With it, we don&rsquo;t need to manually create DNS entries every time we deploy a new application to our cluster. Cool, right?</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm install external-dns stable/external-dns \
</span></span><span class=line><span class=cl>  --create-namespace \
</span></span><span class=line><span class=cl>  --namespace external-dns \
</span></span><span class=line><span class=cl>  --set provider=aws \
</span></span><span class=line><span class=cl>  --set aws.zoneType=public \
</span></span><span class=line><span class=cl>  --set txtOwnerId=&lt;ZONE_ID&gt;
</span></span><span class=line><span class=cl>  --set policy=sync
</span></span><span class=line><span class=cl>  --set registry=txt
</span></span><span class=line><span class=cl>  --set interval=20s
</span></span><span class=line><span class=cl>  --set domainFilters[0]=&lt;DOMAIN&gt;
</span></span></code></pre></div><p>Replace <code>&lt;ZONE_ID></code> with your AWS Route 53 zone ID and <code>&lt;DOMAIN></code> with your domain in the format <code>domain.com</code>.</p><h3 id=cert-manager>cert-manager</h3><p><strong>cert-manager</strong> is a CRD (Custom Resource Definition) that dynamically generates TLS/SSL certificates for our applications using <a href=https://letsencrypt.org/>Let&rsquo;s Encrypt</a> (although it also supports other issuers).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm repo add bitnami https://charts.bitnami.com/bitnami
</span></span><span class=line><span class=cl>helm install --create-namespace -n cert-manager cert-manager bitnami/cert-manager \
</span></span><span class=line><span class=cl>  --create-namespace \
</span></span><span class=line><span class=cl>  --namespace cert-manager \
</span></span><span class=line><span class=cl>  --set installCRDs=true
</span></span></code></pre></div><p>With the chart installed, it&rsquo;s necessary to create two CRDs, each representing a different issuer from Let&rsquo;s Encrypt, one for production and one for staging. The difference between them is the request limit we can make. In a test environment, prefer to use the staging environment.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>apiVersion: cert-manager.io/v1
</span></span><span class=line><span class=cl>kind: ClusterIssuer
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: letsencrypt-prod
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  acme:
</span></span><span class=line><span class=cl>    server: https://acme-v02.api.letsencrypt.org/directory
</span></span><span class=line><span class=cl>    email: &lt;meu_email&gt;
</span></span><span class=line><span class=cl>    privateKeySecretRef:
</span></span><span class=line><span class=cl>      name: letsencrypt-prod
</span></span><span class=line><span class=cl>    solvers:
</span></span><span class=line><span class=cl>      - http01:
</span></span><span class=line><span class=cl>          ingress:
</span></span><span class=line><span class=cl>            class: nginx
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>apiVersion: cert-manager.io/v1
</span></span><span class=line><span class=cl>kind: ClusterIssuer
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: letsencrypt-staging
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  acme:
</span></span><span class=line><span class=cl>    server: https://acme-staging-v02.api.letsencrypt.org/directory
</span></span><span class=line><span class=cl>    email: &lt;meu_email&gt;
</span></span><span class=line><span class=cl>    privateKeySecretRef:
</span></span><span class=line><span class=cl>      name: letsencrypt-prod
</span></span><span class=line><span class=cl>    solvers:
</span></span><span class=line><span class=cl>      - http01:
</span></span><span class=line><span class=cl>          ingress:
</span></span><span class=line><span class=cl>            class: nginx
</span></span></code></pre></div><blockquote><p>Note: Replace <code>&lt;my_email></code> with your email address. If you&rsquo;re using an Ingress other than Nginx, you need to change the manifests above by setting the appropriate class.</p></blockquote><p>Run the command <code>kubectl apply -f cert-manager-staging.yaml -f cert-manager-prod.yaml</code> to create them in the cluster.</p><h2 id=nginx-ingress-controller>NGINX Ingress Controller</h2><p>We allow access to our applications through the <strong>NGINX Ingress Controller</strong>. You can think of an Ingress as a reverse proxy.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm upgrade --install ingress-nginx ingress-nginx \
</span></span><span class=line><span class=cl>  --repo https://kubernetes.github.io/ingress-nginx \
</span></span><span class=line><span class=cl>  --namespace ingress-nginx \
</span></span><span class=line><span class=cl>  --create-namespace
</span></span></code></pre></div><h2 id=auto-scaling-group>Auto Scaling Group</h2><p>One of the coolest features of cloud computing is <strong>elasticity</strong>. Imagine that throughout the year, we have a relatively constant demand, but at certain times - like Black Friday - it can increase considerably, and soon you&rsquo;ll need more nodes within your nodegroups to meet the needs of your pods. So that we don&rsquo;t have to do this manually, let&rsquo;s add automatic scaling functionality to our nodegroup.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm repo add autoscaler https://kubernetes.github.io/autoscaler
</span></span><span class=line><span class=cl>helm install --create-namespace -n cluster-autoscaler autoscaler/cluster-autoscaler \
</span></span><span class=line><span class=cl>  --set &#39;autoDiscovery.clusterName=&lt;cluster_name&gt;&#39;
</span></span></code></pre></div><blockquote><p>Note: Replace <code>&lt;cluster_name></code> with the name of your cluster (in this case, <code>demo-eks</code>).</p></blockquote><p>To test, after deploying any application, increase the number of replicas to a number not met by the resources available in your nodegroup. The <strong>cluster-autoscaler</strong> will provide new nodes up to the maximum number set in the nodegroup. When the number of pods consumes less than 50% of the resources of a node for more than 10 minutes, this node will be removed from the nodegroup. Cool, right?</p><h2 id=deploying-an-application>Deploying an Application</h2><p>With our cluster set up and the add-ons installed, it&rsquo;s time to launch a test application. Below are the manifests within a single file named <code>hello-kubernetes.yaml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Namespace
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: hello-kubernetes
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: apps/v1
</span></span><span class=line><span class=cl>kind: Deployment
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  namespace: hello-kubernetes
</span></span><span class=line><span class=cl>  name: hello-kubernetes
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  replicas: 2
</span></span><span class=line><span class=cl>  selector:
</span></span><span class=line><span class=cl>    matchLabels:
</span></span><span class=line><span class=cl>      app: hello-kubernetes
</span></span><span class=line><span class=cl>  template:
</span></span><span class=line><span class=cl>    metadata:
</span></span><span class=line><span class=cl>      labels:
</span></span><span class=line><span class=cl>        app: hello-kubernetes
</span></span><span class=line><span class=cl>    spec:
</span></span><span class=line><span class=cl>      containers:
</span></span><span class=line><span class=cl>      - name: hello-kubernetes
</span></span><span class=line><span class=cl>        image: paulbouwer/hello-kubernetes:1.5
</span></span><span class=line><span class=cl>        ports:
</span></span><span class=line><span class=cl>        - containerPort: 8080
</span></span><span class=line><span class=cl>        resources:
</span></span><span class=line><span class=cl>          requests:
</span></span><span class=line><span class=cl>            memory: &#34;128Mi&#34;
</span></span><span class=line><span class=cl>            cpu: &#34;250m&#34;
</span></span><span class=line><span class=cl>          limits:
</span></span><span class=line><span class=cl>            memory: &#34;256Mi&#34;
</span></span><span class=line><span class=cl>            cpu: &#34;500m&#34;
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Service
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  namespace: hello-kubernetes
</span></span><span class=line><span class=cl>  name: hello-kubernetes
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  type: ClusterIP
</span></span><span class=line><span class=cl>  selector:
</span></span><span class=line><span class=cl>    app: hello-kubernetes
</span></span><span class=line><span class=cl>  ports:
</span></span><span class=line><span class=cl>  - port: 80
</span></span><span class=line><span class=cl>    targetPort: 8080
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: networking.k8s.io/v1
</span></span><span class=line><span class=cl>kind: Ingress
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  namespace: hello-kubernetes
</span></span><span class=line><span class=cl>  name: hello-kubernetes-ingress
</span></span><span class=line><span class=cl>  annotations:
</span></span><span class=line><span class=cl>    nginx.ingress.kubernetes.io/ingress-class: nginx
</span></span><span class=line><span class=cl>    cert-manager.io/cluster-issuer: letsencrypt-prod
</span></span><span class=line><span class=cl>    external-dns.alpha.kubernetes.io/hostname: &lt;app.DOMAIN&gt;
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  tls:
</span></span><span class=line><span class=cl>    - hosts:
</span></span><span class=line><span class=cl>        - &lt;app.DOMAIN&gt;
</span></span><span class=line><span class=cl>      secretName: &lt;app.DOMAIN&gt;
</span></span><span class=line><span class=cl>  rules:
</span></span><span class=line><span class=cl>    - host: &lt;app.DOMAIN&gt;
</span></span><span class=line><span class=cl>      http:
</span></span><span class=line><span class=cl>        paths:
</span></span><span class=line><span class=cl>        - path: /
</span></span><span class=line><span class=cl>          pathType: Prefix
</span></span><span class=line><span class=cl>          backend:
</span></span><span class=line><span class=cl>            service:
</span></span><span class=line><span class=cl>              name: hello-kubernetes
</span></span><span class=line><span class=cl>              port: 
</span></span><span class=line><span class=cl>                number: 80
</span></span></code></pre></div><blockquote><p>Note: Replace &lt;app.DOMAIN> with the domain you want to use for your application, something like app.juliaK8s.net.</p></blockquote><p>Once you&rsquo;ve created the manifest and saved it, deploy the YAML file using <code>kubectl apply</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl apply -f hello-kubernetes.yaml
</span></span></code></pre></div><p>This command will create the resources defined in the YAML file (Namespace, Deployment, Service, Ingress) in your Kubernetes cluster.</p><p>After applying the YAML file, you can verify that the resources have been created successfully by running the command <code>kubectl get all -n hello-kubernetes </code>.</p><p>If everything goes well, here&rsquo;s what should happen:</p><ul><li>Entries will be created in your DNS zone inside AWS Route 53 according to what was configured in your ingress and the settings of your ExternalDNS, and within a few minutes, you will be able to access your application by that name. You can monitor the propagation using the dig tool;</li><li>A certificate will be automatically generated for your application. This can take some time for new applications;</li><li>We allocate two replicas for the application, and here&rsquo;s a very important caveat: Kubernetes will by default perform round-robin load balancing between the pods. In most of today&rsquo;s web applications, we work with sessions and, as a result, there may be scenarios where a user authenticates on one pod, and the next request, is redirected to another where the session does not exist. As a consequence, strange behaviors are presented to the user, such as redirection to the login screen, &ldquo;Unauthorized&rdquo; messages, intermittent access, etc. To prevent this, we usually use some service like <strong>Redis, memcached</strong> (which may or may not be on AWS ElastiCache), or the sticky-sessions feature, where a user is consistently sent to the same pod.</li></ul><h2 id=deleting-cluster>Deleting Cluster</h2><p>If you want to delete the cluster and resources you&rsquo;ve just created, run the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>eksctl delete cluster --name demo-eks --region us-east-1
</span></span></code></pre></div><h2 id=conclusion>Conclusion</h2><p>Kubernetes is an extremely extensive and complex subject with a myriad of possibilities. I presented some of them here that can be used not only in AWS EKS but also in on-premises installations (except for the <strong>cluster-autoscaler</strong>, unless you are using <strong>OpenStack</strong> in your company). There is also a series of security improvements that can be made to the cluster setup in this article. I hope you enjoyed it!</p><p>References</p><ul><li><a href=https://eksctl.io/>eksctl</a></li><li><a href=https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html>Getting started with Amazon EKS – eksctl</a></li></ul><hr><p>If you liked this article, follow me on <a href=https://twitter.com/juliafmorgado>Twitter</a> (where I share my tech journey daily), connect with me on <a href=https://www.linkedin.com/in/juliafmorgado/>LinkedIn</a>, check out my <a href=https://www.instagram.com/juliafmorgado/>IG</a>, and make sure to subscribe to my <a href=https://www.youtube.com/c/JuliaFMorgado>Youtube</a> channel for more amazing content!!</p><h3>Related Posts</h3><ul><li><a href=/posts/deploy-your-first-web-app-on-aws-amplify-lambda-dynamodb-api-gateway/>Deploy Your First Web App on AWS with AWS Amplify, Lambda, DynamoDB and API Gateway</a></li><li><a href=/posts/how-to-pass-kcna-kubernetes-cloud-native-associate/>How to Pass the KCNA - Kubernetes And Cloud Native Associate</a></li><li><a href=/posts/15-options-to-build-kubernetes-playground/>15 Options To Build A Kubernetes Playground</a></li></ul></div><div class=post__footer><span><a class=category href=/categories/tech/>Tech</a></span>
<span><a class=tag href=/tags/aws/>AWS</a><a class=tag href=/tags/eks/>EKS</a><a class=tag href=/tags/kubernetes/>Kubernetes</a></span></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Julia F Morgado 2024</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-H2FSKPLDX2"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-H2FSKPLDX2")</script></body></html>